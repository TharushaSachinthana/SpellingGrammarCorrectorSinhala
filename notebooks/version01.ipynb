{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Step 1: Scrape vocabulary from the website\n",
    "def scrape_vocab(url, file_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        word_list = []\n",
    "        for table in soup.find_all(\"table\"):\n",
    "            for row in table.find_all(\"tr\"):\n",
    "                cells = row.find_all(\"td\")\n",
    "                if len(cells) >= 2:\n",
    "                    sinhala_word = cells[1].get_text(strip=True)\n",
    "                    word_list.append(sinhala_word)\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(\"\\n\".join(word_list))\n",
    "        print(f\"Scraped {len(word_list)} Sinhala words and saved to {file_path}.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch the webpage. Status code: {response.status_code}\")\n",
    "\n",
    "# Scrape Sinhala vocabulary and save\n",
    "sinhala_vocab_path = \"/content/drive/MyDrive/AI/project/sinhala_vocab.txt\"\n",
    "scrape_vocab(\"https://mylanguages.org/learn_sinhala.php\", sinhala_vocab_path)\n",
    "\n",
    "# Step 2: Load dataset vocabulary\n",
    "file_path = \"/content/drive/MyDrive/AI/project/data-spell-checker.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "correct_words = data[data['label'] == 1]['word'].str.strip().tolist()\n",
    "dataset_vocab = set(correct_words)\n",
    "\n",
    "# Step 3: Load vocabulary from scraped file\n",
    "if os.path.exists(sinhala_vocab_path):\n",
    "    with open(sinhala_vocab_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        scraped_vocab = set(file.read().splitlines())\n",
    "else:\n",
    "    scraped_vocab = set()\n",
    "\n",
    "# Combine vocabularies\n",
    "vocab = dataset_vocab.union(scraped_vocab)\n",
    "print(f\"Combined Vocabulary Size: {len(vocab)}\")\n",
    "\n",
    "# Step 4: Define spell-checker functions\n",
    "always_correct_triggers = {\"නම\", \"ගම\"}  # Words after these are always correct\n",
    "\n",
    "def edit_distance(word1, word2):\n",
    "    dp = np.zeros((len(word1) + 1, len(word2) + 1), dtype=int)\n",
    "    for i in range(len(word1) + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(len(word2) + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, len(word1) + 1):\n",
    "        for j in range(1, len(word2) + 1):\n",
    "            cost = 0 if word1[i - 1] == word2[j - 1] else 1\n",
    "            dp[i][j] = min(dp[i - 1][j] + 1,       # Deletion\n",
    "                           dp[i][j - 1] + 1,       # Insertion\n",
    "                           dp[i - 1][j - 1] + cost)  # Substitution\n",
    "    return dp[len(word1)][len(word2)]\n",
    "\n",
    "def correct_word(word, vocab, max_distance=2):\n",
    "    if word in vocab:\n",
    "        return word\n",
    "    closest_word = None\n",
    "    min_distance = float(\"inf\")\n",
    "    for v_word in vocab:\n",
    "        distance = edit_distance(word, v_word)\n",
    "        if distance < min_distance and distance <= max_distance:\n",
    "            min_distance = distance\n",
    "            closest_word = v_word\n",
    "    return closest_word if closest_word else word\n",
    "\n",
    "def spell_check(sentence, vocab, max_distance=2):\n",
    "    words = sentence.split()\n",
    "    corrected_words = []\n",
    "    skip_correction = False\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if skip_correction and word.endswith(\".\"):\n",
    "            skip_correction = False\n",
    "        if i > 0 and words[i - 1] in always_correct_triggers:\n",
    "            skip_correction = True\n",
    "        if skip_correction:\n",
    "            corrected_words.append(word)\n",
    "        else:\n",
    "            corrected_words.append(correct_word(word, vocab, max_distance))\n",
    "    return \" \".join(corrected_words)\n",
    "\n",
    "# Step 5: User input loop\n",
    "print(\"Sinhala Spell Checker with Contextual Rules\")\n",
    "print(\"Type 'exit' to quit.\")\n",
    "while True:\n",
    "    user_input = input(\"Enter a Sinhala sentence: \").strip()\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    corrected_output = spell_check(user_input, vocab)\n",
    "    print(f\"Corrected Output: {corrected_output}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
